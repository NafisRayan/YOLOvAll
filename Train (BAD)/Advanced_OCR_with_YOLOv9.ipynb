{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-05-30T21:58:43.368338Z",
          "iopub.status.busy": "2024-05-30T21:58:43.367965Z",
          "iopub.status.idle": "2024-05-30T21:58:44.470056Z",
          "shell.execute_reply": "2024-05-30T21:58:44.469032Z"
        },
        "id": "5K3RpdG5xUmC",
        "outputId": "b92fb9e5-4893-4a28-8eb7-2f14afe05652",
        "papermill": {
          "duration": 1.110473,
          "end_time": "2024-05-30T21:58:44.472854",
          "exception": false,
          "start_time": "2024-05-30T21:58:43.362381",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'nvidia-smi' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-05-30T21:58:44.482922Z",
          "iopub.status.busy": "2024-05-30T21:58:44.482074Z",
          "iopub.status.idle": "2024-05-30T21:59:01.590038Z",
          "shell.execute_reply": "2024-05-30T21:59:01.588683Z"
        },
        "id": "C2Yge4kMxUmD",
        "outputId": "2030ae0e-0f68-45a3-97da-ee2a1bafee78",
        "papermill": {
          "duration": 17.115401,
          "end_time": "2024-05-30T21:59:01.592464",
          "exception": false,
          "start_time": "2024-05-30T21:58:44.477063",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.55-py3-none-any.whl (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.2/800.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.25.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 ultralytics-8.2.55 ultralytics-thop-2.0.0\n"
          ]
        }
      ],
      "source": [
        "%pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-05-30T21:59:01.606289Z",
          "iopub.status.busy": "2024-05-30T21:59:01.605856Z",
          "iopub.status.idle": "2024-05-30T21:59:20.828301Z",
          "shell.execute_reply": "2024-05-30T21:59:20.827121Z"
        },
        "id": "tD8dKk--xUmE",
        "outputId": "b100d9aa-59fc-4173-c212-54b952627edc",
        "papermill": {
          "duration": 19.232041,
          "end_time": "2024-05-30T21:59:20.830532",
          "exception": false,
          "start_time": "2024-05-30T21:59:01.598491",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.2.36  Python-3.9.6 torch-2.1.2+cpu CPU (AMD Ryzen 5 4500U with Radeon Graphics)\n",
            "Setup complete  (6 CPUs, 7.4 GB RAM, 99.1/99.2 GB disk)\n"
          ]
        }
      ],
      "source": [
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-30T21:59:20.844751Z",
          "iopub.status.busy": "2024-05-30T21:59:20.843822Z",
          "iopub.status.idle": "2024-05-30T21:59:20.848658Z",
          "shell.execute_reply": "2024-05-30T21:59:20.847549Z"
        },
        "id": "CwMUVSfCxUmF",
        "papermill": {
          "duration": 0.014481,
          "end_time": "2024-05-30T21:59:20.850982",
          "exception": false,
          "start_time": "2024-05-30T21:59:20.836501",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-30T21:59:20.864783Z",
          "iopub.status.busy": "2024-05-30T21:59:20.864394Z",
          "iopub.status.idle": "2024-05-30T21:59:22.045773Z",
          "shell.execute_reply": "2024-05-30T21:59:22.044642Z"
        },
        "id": "h1_8GO5LxUmF",
        "papermill": {
          "duration": 1.191387,
          "end_time": "2024-05-30T21:59:22.048429",
          "exception": false,
          "start_time": "2024-05-30T21:59:20.857042",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"yolov9c.yaml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7Sn01iIsxkLs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_W6X8G1xzfn"
      },
      "source": [
        "# Dataset Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hbWtZxsnxXOE"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYUMcjl20UNR",
        "outputId": "d29feae6-ee5f-49fd-d400-73716e727206"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading textocr-text-extraction-from-images-dataset, 7224184156 bytes compressed\n",
            "[===                                               ] 484106240 bytes downloaded"
          ]
        }
      ],
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'textocr-text-extraction-from-images-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F2327240%2F3919937%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240712%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240712T192749Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D0f69a4714fe34fd3576d74bc25fa4bd773cd97888f17207912d42babd8074fa210f216f05463b471035da5e9688e2b1d2e9625743e673bfb2498443fdebd16e85e0c554d080c8ffb10376830a565ada68277bef96381327ed2b847b45335dc6ad76d74201469cd2b2fcf95c331f9ed839e49b240705832f91a49af28a69082e81a9752a55a70c71e3e21b5236be5e940ac2b31b13069ceec43ad1c1c77bd85c3a6ca38627c044ab4bbc29afda8a7be456d7990d3f0689fec68ed894a15a96f7f57812758f8d29e6e4adad7d88b39fb9fcd7c941650469b843beb3414696b41d61868207c8bc942a916ba21428c8c443944693636b0a242275eeff996a75d4c8e'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrGeA4EXxjQE"
      },
      "outputs": [],
      "source": [
        "path = \"/kaggle/input/textocr-text-extraction-from-images-dataset/\"\n",
        "temp = pd.read_csv(path+\"annot.csv\")\n",
        "df = pd.read_csv(path+\"img.csv\")\n",
        "df[\"bbox\"] = temp[\"bbox\"]\n",
        "df.head(5)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmB62kAOxrWX"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df[\"file_name\"] = df[\"file_name\"].str.replace(\"train/\", \"\")\n",
        "df.drop([\"set\"], axis=1, inplace=True)\n",
        "# Split data\n",
        "train, val = train_test_split(df, test_size=0.2, random_state=42)\n",
        "train.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
        "val.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
        "# Save the splits to text files\n",
        "train.to_csv('train.csv')\n",
        "val.to_csv('val.csv')\n",
        "\n",
        "temp = pd.read_csv(\"train.csv\")\n",
        "temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LjRM7ZAxwTt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "# /kaggle/input/textocr-text-extraction-from-images-dataset/train_val_images/train_images/0000599864fd15b3.jpg\n",
        "# Load the dataframe containing training dataset filenames\n",
        "train_df = pd.read_csv('train.csv')  # Update the filename as per your actual file\n",
        "\n",
        "# Load the dataframe containing validation dataset filenames\n",
        "val_df = pd.read_csv('val.csv')  # Update the filename as per your actual file\n",
        "\n",
        "# Define source directory containing all images\n",
        "source_dir = '/kaggle/input/textocr-text-extraction-from-images-dataset/train_val_images/train_images/'\n",
        "\n",
        "# Define destination directories for training and validation images\n",
        "train_dir = '/kaggle/working/train/images'\n",
        "val_dir = '/kaggle/working/val/images'\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "\n",
        "# Move training images to the training directory\n",
        "for index, row in train_df.iterrows():\n",
        "    filename = row['file_name']\n",
        "    src_path = os.path.join(source_dir, filename)\n",
        "    dst_path = os.path.join(train_dir, filename)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "# Move validation images to the validation directory\n",
        "for index, row in val_df.iterrows():\n",
        "    filename = row['file_name']\n",
        "    src_path = os.path.join(source_dir, filename)\n",
        "    dst_path = os.path.join(val_dir, filename)\n",
        "    shutil.copy(src_path, dst_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8hJyxPrx7ov"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Define directory containing images and labels\n",
        "image_dir = 'train'  # Update with the directory containing training images\n",
        "label_dir = '/kaggle/working/train/labels'  # Update with the directory where you want to save label files\n",
        "os.makedirs(label_dir, exist_ok=True)\n",
        "\n",
        "# Function to convert bounding box coordinates to YOLO format\n",
        "def convert_to_yolo_format(bbox, image_width, image_height):\n",
        "    # Parse the bounding box coordinates as a list of floats\n",
        "    bbox = [float(coord) for coord in bbox.strip('[]').split(',')]\n",
        "    x_center = bbox[0] + bbox[2] / 2\n",
        "    y_center = bbox[1] + bbox[3] / 2\n",
        "    width = bbox[2]\n",
        "    height = bbox[3]\n",
        "    # Normalize coordinates\n",
        "    x_center /= image_width\n",
        "    y_center /= image_height\n",
        "    width /= image_width\n",
        "    height /= image_height\n",
        "    return x_center, y_center, width, height\n",
        "\n",
        "# Iterate over DataFrame rows and create label files\n",
        "for index, row in train.iterrows():\n",
        "    image_filename = row['file_name']\n",
        "    image_width = row['width']\n",
        "    image_height = row['height']\n",
        "    label_filename = os.path.splitext(image_filename)[0] + '.txt'\n",
        "    label_filepath = os.path.join(label_dir, label_filename)\n",
        "    with open(label_filepath, 'w') as label_file:\n",
        "        bbox = row['bbox']  # Assuming bbox column contains list of bounding box coordinates\n",
        "        x_center, y_center, width, height = convert_to_yolo_format(bbox, image_width, image_height)\n",
        "        label_file.write(f\"0 {x_center} {y_center} {width} {height}\\n\")  # Assuming only one class (class_id=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0v5nZTbcxk5X"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Define directory containing images and labels\n",
        "image_dir = 'val'  # Update with the directory containing training images\n",
        "label_dir = '/kaggle/working/val/labels'  # Update with the directory where you want to save label files\n",
        "os.makedirs(label_dir, exist_ok=True)\n",
        "\n",
        "# Function to convert bounding box coordinates to YOLO format\n",
        "def convert_to_yolo_format(bbox, image_width, image_height):\n",
        "    # Parse the bounding boxa coordinates as a list of floats\n",
        "    bbox = [float(coord) for coord in bbox.strip('[]').split(',')]\n",
        "    x_center = bbox[0] + bbox[2] / 2\n",
        "    y_center = bbox[1] + bbox[3] / 2\n",
        "    width = bbox[2]\n",
        "    height = bbox[3]\n",
        "    # Normalize coordinates\n",
        "    x_center /= image_width\n",
        "    y_center /= image_height\n",
        "    width /= image_width\n",
        "    height /= image_height\n",
        "    return x_center, y_center, width, height\n",
        "\n",
        "# Iterate over DataFrame rows and create label files\n",
        "for index, row in val.iterrows():\n",
        "    image_filename = row['file_name']\n",
        "    image_width = row['width']\n",
        "    image_height = row['height']\n",
        "    label_filename = os.path.splitext(image_filename)[0] + '.txt'\n",
        "    label_filepath = os.path.join(label_dir, label_filename)\n",
        "    with open(label_filepath, 'w') as label_file:\n",
        "        bbox = row['bbox']  # Assuming bbox column contains list of bounding box coordinates\n",
        "        x_center, y_center, width, height = convert_to_yolo_format(bbox, image_width, image_height)\n",
        "        label_file.write(f\"0 {x_center} {y_center} {width} {height}\\n\")  # Assuming only one class (class_id=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXbvAs5uyAQn"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "data = {\n",
        "    'train': \"/kaggle/working/train\",\n",
        "    'val': '/kaggle/working/val',\n",
        "    'nc': 1,\n",
        "    'names': ['text']\n",
        "}\n",
        "\n",
        "# Write to a YAML file\n",
        "with open('data.yaml', 'w') as file:\n",
        "    yaml.dump(data, file, default_flow_style=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaX6CCHtyDK0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FBXVE1MyAcv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp-KC3inyO7V"
      },
      "source": [
        "# Training Start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-30T21:59:22.063105Z",
          "iopub.status.busy": "2024-05-30T21:59:22.06205Z",
          "iopub.status.idle": "2024-05-31T01:24:54.227017Z",
          "shell.execute_reply": "2024-05-31T01:24:54.22601Z"
        },
        "id": "7Dko6xjzxUmF",
        "papermill": {
          "duration": 12332.175058,
          "end_time": "2024-05-31T01:24:54.229912",
          "exception": false,
          "start_time": "2024-05-30T21:59:22.054854",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# results = model.train(data=\"/kaggle/input/plate-yaml/plate_data.yaml\",epochs=50)\n",
        "\n",
        "results = model.train(data=\"data.yaml\",epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9BT0kn7ywKd"
      },
      "outputs": [],
      "source": [
        "shutil.copy(\"/kaggle/input/imagedata/download.jpeg\", \"/kaggle/working/\")\n",
        "!yolo task=detect mode=predict model=best.pt show=True conf=0.5 source=download.jpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6krjbiVyvKq"
      },
      "outputs": [],
      "source": [
        "!pip install Pillow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kciWXi9RyvUW"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Open the JPEG image\n",
        "image_path = \"/kaggle/working/runs/detect/predict/download.jpeg\"\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Display the image\n",
        "image.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_V98sXFZy7S5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ba6NwCyOy7lH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAWzkmxJyvc3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-31T01:24:59.540252Z",
          "iopub.status.busy": "2024-05-31T01:24:59.539888Z",
          "iopub.status.idle": "2024-05-31T01:25:00.303912Z",
          "shell.execute_reply": "2024-05-31T01:25:00.302834Z"
        },
        "id": "Hjc22gZExUmF",
        "papermill": {
          "duration": 3.427803,
          "end_time": "2024-05-31T01:25:00.306085",
          "exception": false,
          "start_time": "2024-05-31T01:24:56.878282",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "img = mpimg.imread('/kaggle/working/runs/detect/train/results.png')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tx-KYbGPxUmG"
      },
      "outputs": [],
      "source": [
        "!yolo task=detect mode=predict model='/kaggle/working/runs/detect/train/weights/best.pt' conf=0.25 source='/kaggle/input/plate-license/SYN-2/test/images' save=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-31T01:25:05.527462Z",
          "iopub.status.busy": "2024-05-31T01:25:05.527038Z",
          "iopub.status.idle": "2024-05-31T01:25:15.458825Z",
          "shell.execute_reply": "2024-05-31T01:25:15.456996Z"
        },
        "id": "myfj0Vk6xUmG",
        "papermill": {
          "duration": 12.501088,
          "end_time": "2024-05-31T01:25:15.490202",
          "exception": true,
          "start_time": "2024-05-31T01:25:02.989114",
          "status": "failed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "directory='/kaggle/working/runs/detect/predict'\n",
        "plt.figure(figsize=(40, 40))\n",
        "for i, file in enumerate(os.listdir(directory)[0:9]):\n",
        "    fullpath = directory + \"/\" + file\n",
        "    img=mpimg.imread(fullpath)\n",
        "    ax=plt.subplot(3,3,i+1)\n",
        "    plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GGoo89bxUmG",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 5120291,
          "sourceId": 8564815,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 5120301,
          "sourceId": 8564841,
          "sourceType": "datasetVersion"
        }
      ],
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 12400.93599,
      "end_time": "2024-05-31T01:25:21.164436",
      "environment_variables": {},
      "exception": true,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-05-30T21:58:40.228446",
      "version": "2.5.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
